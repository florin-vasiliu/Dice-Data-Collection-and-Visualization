{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                job_title:  ETL Data Analyst ,\n",
      "                job_company:  Signature Consultants ,\n",
      "                job_salary: $45.00 - $55.00 per hour,\n",
      "                job_location:  Charlotte, NC, USA,\n",
      "                job_date: 1 hour ago,\n",
      "                job_description: \n",
      "ETL Data Analyst Summary:Sign\n",
      "\n",
      "                job_title:  Data Analyst ,\n",
      "                job_company:  Experis ,\n",
      "                job_salary: ,\n",
      "                job_location:  White Plains, NY, USA,\n",
      "                job_date: 1 hour ago,\n",
      "                job_description: \n",
      "Data AnalystWe're hiring expe\n",
      "                job_title:  Data Analyst ,\n",
      "                job_company:  Experis ,\n",
      "                job_salary: ,\n",
      "                job_location:  Cupertino, CA, USA,\n",
      "                job_date: 1 hour ago,\n",
      "                job_description: \n",
      "Hello,Hope you are doing well\n",
      "\n",
      "\n",
      "                job_title:  Data Analyst and Reporter ,\n",
      "                job_company:  Michael Page International ,\n",
      "                job_salary: $1 - $90 per annum,\n",
      "                job_location:  New York, NY, USA,\n",
      "                job_date: 2 hours ago,\n",
      "                job_description: \n",
      "MPI does not discriminate on \n",
      "\n",
      "                job_title:  Data Analyst ,\n",
      "                job_company:  Beacon Hill Technologies ,\n",
      "                job_salary: ,\n",
      "                job_location:  Wilmington, DE, USA,\n",
      "                job_date: 2 hours ago,\n",
      "                job_description: \n",
      "Our client in Wilmington, DE \n",
      "\n",
      "                job_title:  Data Analyst ,\n",
      "                job_company:  Agile ,\n",
      "                job_salary: ,\n",
      "                job_location:  Atlanta, GA, USA,\n",
      "                job_date: 2 hours ago,\n",
      "                job_description: \n",
      "Data AnalystOur client is a d\n",
      "\n",
      "                job_title:  Business Data Analyst ,\n",
      "                job_company:  Signature Consultants ,\n",
      "                job_salary: ,\n",
      "                job_location:  Dallas, TX, USA,\n",
      "                job_date: 1 hour ago,\n",
      "                job_description: \n",
      "Business Data Analyst Summary\n",
      "\n",
      "                job_title:  Data Analyst ,\n",
      "                job_company:  Honu Services ,\n",
      "                job_salary: ,\n",
      "                job_location:  Omaha, NE, USA,\n",
      "                job_date: 2 hours ago,\n",
      "                job_description: \n",
      "Position/Job Title: Data Anal\n",
      "\n",
      "                job_title:  Mainframe Data Analyst | Mainframe DB2 COBOL JCL SQL | in NY and NC ,\n",
      "                job_company:  Quality IT Source, LLC ,\n",
      "                job_salary: $50 - $60,\n",
      "                job_location:  Charlotte, NC, USA,\n",
      "                job_date: 10 hours ago,\n",
      "                job_description: \n",
      "Looking for a Mainframe Data \n",
      "\n",
      "                job_title:  SAP Data Analyst ,\n",
      "                job_company:  Zaspar Technologies ,\n",
      "                job_salary: Depends on Experience,\n",
      "                job_location:  Alameda, CA, USA,\n",
      "                job_date: 2 days ago,\n",
      "                job_description: \n",
      "Job Title: SAP Data Analyst L\n",
      "\n",
      "                job_title:  Data Analyst Specialist ,\n",
      "                job_company:  CompuGain Corporation ,\n",
      "                job_salary: $65 hr,\n",
      "                job_location:  McLean, VA, USA,\n",
      "                job_date: 4 hours ago,\n",
      "                job_description: \n",
      "\t\t\tData Analyst This role wil\n",
      "\n",
      "                job_title:  SQL Data Analyst ,\n",
      "                job_company:  Vaco Technology ,\n",
      "                job_salary: $55000 - $60000 per annum,\n",
      "                job_location:  Irvine, CA, USA,\n",
      "                job_date: 1 hour ago,\n",
      "                job_description: \n",
      "*****This is a full time role\n",
      "\n",
      "                job_title:  Urgent Need - Data Engineer, Data Scientist & Data Analyst (Multiple Openings) ,\n",
      "                job_company:  Parmesoft Inc. ,\n",
      "                job_salary: Depends on Experience,\n",
      "                job_location:  Irving, TX, USA,\n",
      "                job_date: 13 hours ago,\n",
      "                job_description: \n",
      "Very Very Urgent..... Please \n",
      "\n",
      "                job_title:  Annuity Data Analyst ,\n",
      "                job_company:  Signature Consultants ,\n",
      "                job_salary: $100000 - $120000 per annum,\n",
      "                job_location:  Des Moines, IA, USA,\n",
      "                job_date: 1 hour ago,\n",
      "                job_description: \n",
      "Annuity Data Analyst:Signatur\n",
      "\n",
      "                job_title:  Data Analyst ,\n",
      "                job_company:  Triune Infomatics Inc ,\n",
      "                job_salary: BASED ON EXPERIENCE,\n",
      "                job_location:  Redwood City, CA, USA,\n",
      "                job_date: 4 hours ago,\n",
      "                job_description: \n",
      "If interested then pl. share \n",
      "\n",
      "                        time_elapsed[s]: 8.124112129211426\n",
      "                        \n",
      "\n",
      "                    key word: data+analyst,\n",
      "                    loop#: 0\n",
      "                    page = 0.0 / 20\n",
      "\n",
      "                job_title:  Data Analyst ,\n",
      "                job_company:  Leidos ,\n",
      "                job_salary: ,\n",
      "                job_location:  Oklahoma City, OK, USA,\n",
      "                job_date: 11 hours ago,\n",
      "                job_description: \n",
      "Description Job Description:L\n",
      "\n",
      "                job_title:  Jr. Data Analyst ,\n",
      "                job_company:  CGI Group, Inc. ,\n",
      "                job_salary: ,\n",
      "                job_location:  Chantilly, VA, USA,\n",
      "                job_date: 3 days ago,\n",
      "                job_description: \n",
      "\t\t\tMeet our professionals CGI\n",
      "\n",
      "                job_title:  Business Data Analyst ,\n",
      "                job_company:  Javen Technologies, Inc ,\n",
      "                job_salary: Depends on Experience,\n",
      "                job_location:  Saint Paul, MN, USA,\n",
      "                job_date: 2 days ago,\n",
      "                job_description: \n",
      "Seeking a Business data analy\n",
      "\n",
      "                job_title:  IT Data Analyst ,\n",
      "                job_company:  Ascent Services Group ,\n",
      "                job_salary: BASED ON EXPERIENCE,\n",
      "                job_location:  Denver, CO, USA,\n",
      "                job_date: 4 hours ago,\n",
      "                job_description: \n",
      "Job Req #: 20-06213Job Descri\n",
      "\n",
      "                job_title:  HCC Data Analyst ,\n",
      "                job_company:  Experis ,\n",
      "                job_salary: ,\n",
      "                job_location:  Pearland, TX, USA,\n",
      "                job_date: 1 hour ago,\n",
      "                job_description: \n",
      "Experis A ManpowerGroup is cu\n",
      "\n",
      "                job_title:  Data Analyst ,\n",
      "                job_company:  Vector Consulting, Inc ,\n",
      "                job_salary: Depends on Experience,\n",
      "                job_location:  Richmond, VA, USA,\n",
      "                job_date: 1 day ago,\n",
      "                job_description: \n",
      "Remote till COVIDOur Governme\n",
      "\n",
      "                job_title:  Data Analyst- Distribution/Licensing ,\n",
      "                job_company:  Genuent Global, LLC ,\n",
      "                job_salary: BASED ON EXPERIENCE,\n",
      "                job_location:  Burbank, CA, USA,\n",
      "                job_date: 4 hours ago,\n",
      "                job_description: \n",
      "Genuent is hiring a Data Anal\n",
      "\n",
      "                job_title:  Solar Data Analyst ,\n",
      "                job_company:  Genuent Global, LLC ,\n",
      "                job_salary: $90000 - $115000 yr,\n",
      "                job_location:  Redwood City, CA, USA,\n",
      "                job_date: 4 hours ago,\n",
      "                job_description: \n",
      "Genuent is hiring a Data Anal\n",
      "\n",
      "                job_title:  Sr Data Analyst - San Mateo, CA ,\n",
      "                job_company:  SPIN Analytics and Strategy ,\n",
      "                job_salary: ,\n",
      "                job_location:  San Mateo, CA, USA,\n",
      "                job_date: 48 minutes ago,\n",
      "                job_description: \n",
      "Data Analyst - Data Analyst S\n",
      "\n",
      "                job_title:  Senior Data Analyst ,\n",
      "                job_company:  Collabera ,\n",
      "                job_salary: ,\n",
      "                job_location:  Charlotte, NC, USA,\n",
      "                job_date: 11 hours ago,\n",
      "                job_description: \n",
      "\t\t\tCharlotte, North CarolinaS\n",
      "\n",
      "                job_title:  Data Analyst with Collibra ,\n",
      "                job_company:  Exafluence ,\n",
      "                job_salary: Depends on Experience,\n",
      "                job_location:  Columbia, SC, USA,\n",
      "                job_date: 2 days ago,\n",
      "                job_description: \n",
      "Hi,           We have urgent,\n",
      "\n",
      "                job_title:  Healthcare Information and Data Analyst II ,\n",
      "                job_company:  Experis ,\n",
      "                job_salary: ,\n",
      "                job_location:  Pearland, TX, USA,\n",
      "                job_date: 1 hour ago,\n",
      "                job_description: \n",
      "Experis A ManpowerGroup is cu\n",
      "\n",
      "                job_title:  Data Analyst with Data Governance Exp ,\n",
      "                job_company:  Exafluence ,\n",
      "                job_salary: Depends on Experience,\n",
      "                job_location:  Columbia, SC, USA,\n",
      "                job_date: 2 days ago,\n",
      "                job_description: \n",
      "Hi,           We have urgent,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                job_title:  Data Analyst ,\n",
      "                job_company:  C2S Technologies Inc ,\n",
      "                job_salary: Depends on Experience,\n",
      "                job_location:  Raleigh, NC, USA,\n",
      "                job_date: 2 days ago,\n",
      "                job_description: \n",
      "C2S Technologies is currently\n",
      "\n",
      "                job_title:  Data Analyst ,\n",
      "                job_company:  Innovative Information Technologies, Inc ,\n",
      "                job_salary: Depends on Experience,\n",
      "                job_location:  Boston, MA, USA,\n",
      "                job_date: 2 days ago,\n",
      "                job_description: \n",
      "Position : Data AnalystLocati\n",
      "\n",
      "                        time_elapsed[s]: 12.360681056976318\n",
      "                        \n",
      "\n",
      "                    key word: data+analyst,\n",
      "                    loop#: 0\n",
      "                    page = 1.0 / 20\n",
      "\n",
      "                        time_elapsed[s]: 13.535958290100098\n",
      "                        \n",
      "\n",
      "                    key word: data+analyst,\n",
      "                    loop#: 0\n",
      "                    page = 2.0 / 20\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\runpy.py\u001b[0m in \u001b[0;36m_run_module_as_main\u001b[1;34m(mod_name, alter_argv)\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     return _run_code(code, main_globals, None,\n\u001b[1;32m--> 193\u001b[1;33m                      \"__main__\", mod_spec)\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m def run_module(mod_name, init_globals=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\runpy.py\u001b[0m in \u001b[0;36m_run_code\u001b[1;34m(code, run_globals, init_globals, mod_name, mod_spec, pkg_name, script_name)\u001b[0m\n\u001b[0;32m     83\u001b[0m                        \u001b[0m__package__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpkg_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                        __spec__ = mod_spec)\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_globals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrun_globals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mipykernel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkernelapp\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaunch_new_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\u001b[0m in \u001b[0;36mlaunch_instance\u001b[1;34m(cls, argv, **kwargs)\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[0mapp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m         \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m         \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;31m#-----------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio_loop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mioloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIOLoop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_logging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masyncio_loop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masyncio_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_forever\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_loop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36mrun_forever\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[0mevents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_running_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    535\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stopping\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36m_run_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1733\u001b[0m                            timeout * 1e3, dt * 1e3)\n\u001b[0;32m   1734\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1735\u001b[1;33m             \u001b[0mevent_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1736\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\selectors.py\u001b[0m in \u001b[0;36mselect\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\selectors.py\u001b[0m in \u001b[0;36m_select\u001b[1;34m(self, r, w, _, timeout)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'win32'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyppeteer\\launcher.py\u001b[0m in \u001b[0;36m_close_process\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_close_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchromeClosed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkillChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;31m# don't forget to close browser process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_done_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_run_until_complete_cb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_forever\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnew_task\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcancelled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36mrun_forever\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'This event loop is already running'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             raise RuntimeError(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import pymongo\n",
    "import time\n",
    "import concurrent.futures\n",
    "from datetime import date, timedelta\n",
    "import re\n",
    "from requests_html import AsyncHTMLSession\n",
    "import pyppdf.patch_pyppeteer\n",
    "\n",
    "class db_connection:\n",
    "    def __init__(self):\n",
    "        #connect to database\n",
    "        connection_string='mongodb://localhost:27017'\n",
    "        client = pymongo.MongoClient(connection_string)\n",
    "        #define database for storage\n",
    "        db = client.dice_db\n",
    "        #drop all stored data\n",
    "        db.jobs.drop()\n",
    "        db.jobs\n",
    "        #define collection to store data\n",
    "        self.jobs_collection = db.jobs\n",
    "\n",
    "    def store_job(self, title, company, salary, location, date, description):\n",
    "        self.jobs_collection.insert_one({ \\\n",
    "        \"job_title\": title, \\\n",
    "        \"job_company\": company, \\\n",
    "        \"job_salary\": salary, \\\n",
    "        \"job_location\": location, \\\n",
    "        \"job_date\": date, \\\n",
    "        \"job_description\": description \\\n",
    "        })\n",
    "\n",
    "async def scrape_job_cards_dice(asession, search_string, location, start_page):\n",
    "    \n",
    "    #query URL\n",
    "    url = f\"\"\"https://www.dice.com/jobs?q={search_string}&{location}&radius=30&radiusUnit=mi&page={start_page}&pageSize=20&language=en\"\"\"\n",
    "\n",
    "    #get asinchronous request from search page\n",
    "    r = await asession.get(url)\n",
    "    \n",
    "    # perform response rendering (running javascripts)\n",
    "    await r.html.arender()\n",
    "\n",
    "    #parse request to BeautifulSoup object\n",
    "    soup = bs(r.html.html, 'html.parser')\n",
    "\n",
    "    #get page job cards\n",
    "    return soup.find_all('div', class_=\"card\")  \n",
    "\n",
    "def scrape_job_dice(job_card):\n",
    "    #initiate fields\n",
    "    job_title = \"\"\n",
    "    job_company = \"\"\n",
    "    job_salary = \"\"\n",
    "    job_location = \"\"\n",
    "    job_date = \"\"\n",
    "    job_description = \"\"\n",
    "\n",
    "    job_title = job_card.find_all(class_=\"card-title-link\")[0].text\n",
    "    job_company = job_card.find_all(class_=\"card-company\")[0].a.text\n",
    "\n",
    "    # get location\n",
    "    job_location = job_card.find_all(id=\"searchResultLocation\")[0].text\n",
    "\n",
    "    # get full job descr html\n",
    "    job_descr_link = job_card.find_all(class_=\"card-title-link\")[0].get('href')\n",
    "    job_descr_html = requests.get(job_descr_link)\n",
    "    soup = bs(job_descr_html.text, 'html.parser') \n",
    "\n",
    "    #check if salary is present or not\n",
    "    try: \n",
    "        job_salary = soup.find_all(class_=\"mL20\")[0].text\n",
    "    except: \n",
    "        job_salary = ''\n",
    "\n",
    "    # job description\n",
    "    job_description = soup.find_all(id=\"jobdescSec\")[0].get_text()\n",
    "\n",
    "    # job date\n",
    "    job_date = job_card.find_all(class_=\"posted-date\")[0].text\n",
    "\n",
    "    #print all found details\n",
    "\n",
    "    print(f\"\"\"\n",
    "        job_title: {job_title},\n",
    "        job_company: {job_company},\n",
    "        job_salary: {job_salary},\n",
    "        job_location: {job_location},\n",
    "        job_date: {job_date},\n",
    "        job_description: {job_description[:30]}\"\"\")\n",
    "\n",
    "    return [job_title, job_company, job_salary, job_location, job_date, job_description]\n",
    "\n",
    "# Function to run multiple scraping threads\n",
    "def run_thread(thread):\n",
    "    session.store_job(*scrape_job_dice(job_cards[thread]))\n",
    "            \n",
    "\n",
    "# Initiate Indeed Session\n",
    "requests_session = AsyncHTMLSession()\n",
    "\n",
    "#Initiate database session\n",
    "session = db_connection()\n",
    "\n",
    "#query input parameters\n",
    "key_words = [\"data+analyst\", \"data+scientist\", \"excel\", \"python\", \"pandas\", \"matplotlib\", \"sql\", \"postgresql\", \"bootstrap\", \"nosql\", \\\n",
    "    \"mongodb\", \"mongo\", \"javascript\", \"tableau\", \"machine+learning\", \"ml\", \"scikit+learn\", \"scikit\", \"keras\", \"tensorflow\", \"pyspark\", \"natural+language+processing\", \\\n",
    "        \"nlp\", \"big+data\", \"etl\", \"extract+transform+load\", \"amazon+web+services\", \"aws\", \"rds\"]\n",
    "where = \"United+States\"\n",
    "\n",
    "page = 0 #each page has an increment of 10\n",
    "\n",
    "#number of pages to loop through and timer\n",
    "pages_to_loop = 20\n",
    "times_to_loop = 2\n",
    "timer_start = time.time()\n",
    "for key_word in key_words:\n",
    "    loop = 0\n",
    "    while loop < times_to_loop:\n",
    "        page = 0\n",
    "        while page<pages_to_loop*10:\n",
    "            try:\n",
    "                #return data from each job card and store in db\n",
    "                job_cards = await scrape_job_cards_dice(requests_session, key_word, where, page)\n",
    "\n",
    "                # Run single threaded request\n",
    "                # for job_card in job_cards:\n",
    "                #     Scrape and store in db\n",
    "                #     session.store_job(*scrape_job(job_card))\n",
    "\n",
    "\n",
    "                # Run multithreaded request\n",
    "                with concurrent.futures.ThreadPoolExecutor(max_workers=15) as executor:\n",
    "                    thread = [x for x in range(15)]\n",
    "                    executor.map(run_thread, thread)\n",
    "\n",
    "                timer_stop = time.time()\n",
    "                print(f\"\"\"\n",
    "                time_elapsed[s]: {timer_stop - timer_start}\n",
    "                \"\"\")\n",
    "            except:\n",
    "                print(\"page error\")\n",
    "\n",
    "            print(f\"\"\"\n",
    "            key word: {key_word},\n",
    "            loop#: {loop}\n",
    "            page = {page/10} / {pages_to_loop}\"\"\"\n",
    "            )\n",
    "            page+=10\n",
    "        loop+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondaebc7325974e641c78342335c88d5ccce"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
