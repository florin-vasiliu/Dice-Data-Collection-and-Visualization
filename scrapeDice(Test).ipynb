{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import pymongo\n",
    "import time\n",
    "import concurrent.futures\n",
    "from datetime import date, timedelta\n",
    "import re\n",
    "\n",
    "from requests_html import HTMLSession\n",
    "import pyppdf.patch_pyppeteer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_job_cards_dice(session, search_string, location, start_page):\n",
    "    \n",
    "    #query URL\n",
    "    url = f\"\"\"https://www.dice.com/jobs?q={search_string}&{location}&radius=30&radiusUnit=mi&page={start_page}&pageSize=5&language=en\"\"\"\n",
    "\n",
    "    #get synchronous request from search page\n",
    "    r = session.get(url)\n",
    "    \n",
    "    # perform response rendering (running javascripts)\n",
    "    print(f\"page {start_page}\")\n",
    "    print(\"rendering...\")\n",
    "    r.html.render()\n",
    "    print(\"render finished\")\n",
    "\n",
    "    #parse request to BeautifulSoup object\n",
    "    soup = bs(r.html.html, 'html.parser')\n",
    "\n",
    "    #get page job cards\n",
    "    return soup.find_all('div', class_=\"card\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_job_dice(job_card):\n",
    "    #initiate fields\n",
    "    job_title = \"\"\n",
    "    job_company = \"\"\n",
    "    job_salary = \"\"\n",
    "    job_location = \"\"\n",
    "    job_date = \"\"\n",
    "    job_description = \"\"\n",
    "\n",
    "    job_title = job_card.find_all(class_=\"card-title-link\")[0].text\n",
    "    job_company = job_card.find_all(class_=\"card-company\")[0].a.text\n",
    "\n",
    "    # get location\n",
    "    job_location = job_card.find_all(id=\"searchResultLocation\")[0].text\n",
    "\n",
    "    # get full job descr html\n",
    "    job_descr_link = job_card.find_all(class_=\"card-title-link\")[0].get('href')\n",
    "    job_descr_html = requests.get(job_descr_link)\n",
    "    soup = bs(job_descr_html.text, 'html.parser') \n",
    "\n",
    "    #check if salary is present or not\n",
    "    try: \n",
    "        job_salary = soup.find_all(class_=\"mL20\")[0].text\n",
    "    except: \n",
    "        job_salary = ''\n",
    "\n",
    "    # job description\n",
    "    job_description = soup.find_all(id=\"jobdescSec\")[0].get_text()\n",
    "\n",
    "    # job date\n",
    "    job_date = job_card.find_all(class_=\"posted-date\")[0].text\n",
    "\n",
    "    #print all found details\n",
    "\n",
    "    print(f\"\"\"\n",
    "        job_title: {job_title},\n",
    "        job_company: {job_company},\n",
    "        job_salary: {job_salary},\n",
    "        job_location: {job_location},\n",
    "        job_date: {job_date},\n",
    "        job_description: {job_description[:30]}\"\"\")\n",
    "\n",
    "    return [job_title, job_company, job_salary, job_location, job_date, job_description]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_html = HTMLSession()\n",
    "search_string = \"analyst\"\n",
    "location = \"US\"\n",
    "start_page=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in db\n",
    "class db_connection:\n",
    "    def __init__(self):\n",
    "        #connect to database\n",
    "        connection_string='mongodb://localhost:27017'\n",
    "        client = pymongo.MongoClient(connection_string)\n",
    "        #define database for storage\n",
    "        db = client.dice_db\n",
    "        #drop all stored data\n",
    "        db.dice_jobs.drop()\n",
    "        db.dice_jobs\n",
    "        #define collection to store data\n",
    "        self.jobs_collection = db.jobs\n",
    "\n",
    "    def store_job(self, title, company, salary, location, date, description):\n",
    "        self.jobs_collection.insert_one({ \\\n",
    "        \"job_title\": title, \\\n",
    "        \"job_company\": company, \\\n",
    "        \"job_salary\": salary, \\\n",
    "        \"job_location\": location, \\\n",
    "        \"job_date\": date, \\\n",
    "        \"job_description\": description \\\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate database session\n",
    "session = db_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 1\n",
      "rendering...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b8d33e344eb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# start_page=1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# for start_page in range(1,5):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscrape_job_cards_dice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession_html\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_page\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-181da7a0190f>\u001b[0m in \u001b[0;36mscrape_job_cards_dice\u001b[1;34m(session, search_string, location, start_page)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"page {start_page}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"rendering...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"render finished\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\requests_html.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, retries, script, wait, scrolldown, sleep, reload, timeout, keep_page)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \"\"\"\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbrowser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbrowser\u001b[0m  \u001b[1;31m# Automatically create a event loop and browser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\requests_html.py\u001b[0m in \u001b[0;36mbrowser\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_browser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_browser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead."
     ]
    }
   ],
   "source": [
    "# start_page=1\n",
    "# for start_page in range(1,5):\n",
    "scrape_job_cards_dice(session_html, search_string, location, start_page)\n",
    "    \n",
    "    \n",
    "#     # Scrape and store in DB\n",
    "#     cards = page_job_cards\n",
    "    \n",
    "#     for card in cards:\n",
    "#         session.store_job(*scrape_job_dice(card))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape and store in DB\n",
    "cards = await scrape_job_cards_dice(asession, search_string, location, 1)\n",
    "for card in cards:\n",
    "    session.store_job(*scrape_job_dice(card))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape and store in DB\n",
    "cards = await scrape_job_cards_dice(asession, search_string, location, 2)\n",
    "for card in cards:\n",
    "    session.store_job(*scrape_job_dice(card))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # async method\n",
    "# from requests_html import AsyncHTMLSession\n",
    "# import pyppdf.patch_pyppeteer\n",
    "# asession = AsyncHTMLSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #query URL\n",
    "# url = f\"\"\"https://www.dice.com/jobs?q={search_string}&{location}&radius=30&radiusUnit=mi&page={start_page}&pageSize=20&language=en\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # perform page request\n",
    "# r = await asession.get(url)\n",
    "# r.html.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # perform rendering\n",
    "# await r.html.arender()\n",
    "# r.html.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get request from search page\n",
    "# #r = requests_session.get(url)\n",
    "# #r = requests.get(url)\n",
    "# html = r.html.html\n",
    "\n",
    "# #parse request to BeautifulSoup object\n",
    "# soup = bs(html, 'html.parser')\n",
    "\n",
    "# cards = soup.find_all('div', class_=\"card\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for card in cards:\n",
    "#     # job title\n",
    "#     print(card.find_all(class_=\"card-title-link\")[0].text)\n",
    "#     # job descr link\n",
    "#     job_descr_link = card.find_all(class_=\"card-title-link\")[0].get('href')\n",
    "#     print(job_descr_link)\n",
    "#     # job salary\n",
    "#     job_descr_html = requests.get(job_descr_link)\n",
    "#     soup = bs(job_descr_html.text, 'html.parser')  \n",
    "#     try: \n",
    "#         job_salary = soup.find_all(class_=\"mL20\")[0].text\n",
    "#     except: \n",
    "#         job_salary = ''\n",
    "#     print(job_salary)\n",
    "#     # job description\n",
    "#     job_description = soup.find_all(id=\"jobdescSec\")[0].get_text()\n",
    "#     print(job_description)\n",
    "#     # job company\n",
    "#     print(card.find_all(class_=\"card-company\")[0].a.text)\n",
    "#     # job location\n",
    "#     print(card.find_all(id=\"searchResultLocation\")[0].text)\n",
    "#     # job type\n",
    "#     print(card.find_all(class_=\"card-position-type\")[0].text)\n",
    "#     # posted date\n",
    "#     job_date = card.find_all(class_=\"posted-date\")[0].text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
